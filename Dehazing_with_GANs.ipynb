{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "TFE9_P_eB_DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam, Adadelta,RMSprop\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "askGILTwI9dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lMvIMmLbdVe",
        "outputId": "fb4ecae9-6a42-41c4-bdf4-42b1cd5dda3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the datasets"
      ],
      "metadata": {
        "id": "9bOI_y1_CDq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=256\n",
        "def load_images(path):\n",
        "    src_list = list()\n",
        "    print(path)\n",
        "    x=''.join((path,'/'))\n",
        "    print(x)\n",
        "    for filename in  sorted(listdir(path)):\n",
        "        pixels = cv2.imread(x+filename)\n",
        "        pixels = tf.image.resize(pixels, [a, a],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        src_list.append(pixels)\n",
        "    return (src_list)\n",
        "\n",
        "\n",
        "clear='path to directory of clear images'\n",
        "hazy='path to directory of hazy images'\n",
        "clear= load_images(clear)\n",
        "hazy=load_images(hazy)\n",
        "hazy=np.array(hazy,dtype='float32')\n",
        "clear=np.array(clear,dtype='float32')\n",
        "#Pre-processing the images, we want the value of images to be [-1,1]\n",
        "hazy=(hazy - 127.5)/127.5\n",
        "clear=(clear - 127.5)/127.5\n",
        "plt.imshow(0.5*hazy[0]+0.5)\n",
        "plt.show()\n",
        "plt.imshow(0.5*clear[0]+0.5)\n",
        "plt.show()\n",
        "\n",
        "#Splitting the dataset into training and testing phase\n",
        "hazy1=hazy[0:400]\n",
        "clear1=clear[0:400]\n",
        "hazy2=hazy[400:492]\n",
        "clear2=clear[400:492]\n",
        "\n",
        "del hazy\n",
        "del clear\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "JkCHtZPMISX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the loss functions for the generator and discriminator"
      ],
      "metadata": {
        "id": "ep2DnS8aDcwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(y_true,y_pred):\n",
        "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
        "    return real_loss\n",
        "\n",
        "def generator_loss(y_true,y_pred):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
      ],
      "metadata": {
        "id": "PgfT0gQ_7asu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the discriminator, we will be using a Markovian discriminator, in which the output is a grid. This helps preserve spatial information"
      ],
      "metadata": {
        "id": "q4Ess4E9Cfeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_discriminator(image_shape):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tin_src_image = Input(shape=image_shape)\n",
        "\tin_target_image = Input(shape=image_shape)\n",
        "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "\td=GroupNormalization()(d,training=True)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td=GroupNormalization()(d,training=True)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td=GroupNormalization()(d,training=True)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td=ZeroPadding2D()(d)\n",
        "\td = Conv2D(512, (4,4), strides=(1,1), padding='valid', kernel_initializer=init)(d)\n",
        "\td=GroupNormalization()(d,training=True)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td=ZeroPadding2D()(d)\n",
        "\td = Conv2D(1, (4,4),strides=(1,1), padding='valid', kernel_initializer=init)(d)\n",
        "\tpatch_out = Activation('linear')(d)\n",
        "\tmodel = Model([in_src_image, in_target_image], patch_out,name='discriminator')\n",
        "\topt =Adam(learning_rate=0.0002,beta_1=0.5)\n",
        "\tmodel.compile(loss=discriminator_loss, optimizer=opt)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "oKU31baF3JS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the generator, we do so by first defining the encoder blocks for downsampling and then the decoder blocks for upsampling. The generator adopts a U-net architecture with skip connections"
      ],
      "metadata": {
        "id": "enOnvDTUCx5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        " init = RandomNormal(stddev=0.02)\n",
        " g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        " if batchnorm:\n",
        "  g=InstanceNormalization()(g,training=True)\n",
        " g = LeakyReLU(alpha=0.2)(g)\n",
        " return g\n",
        "\n",
        "\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True,norm=True):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tg=layer_in\n",
        "\tif norm:\n",
        "\t\tg=InstanceNormalization()(g,training=True)\n",
        "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.5)(g, training=True)\n",
        "\tg = Concatenate()([g,skip_in])\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g\n",
        "\n",
        "\n",
        "\n",
        "def define_generator(image_shape=(a,a,3)):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\te1 = define_encoder_block(in_image,64,batchnorm=False)\n",
        "\te2 = define_encoder_block(e1, 128)\n",
        "\te3 = define_encoder_block(e2, 256)\n",
        "\te4 = define_encoder_block(e3, 512)\n",
        "\te5 = define_encoder_block(e4, 512,)\n",
        "\te6 = define_encoder_block(e5, 512,)\n",
        "\te7 = define_encoder_block(e6, 512,)\n",
        "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7) #Bottleneck layer\n",
        "\tb = Activation('relu')(b)\n",
        "\td1 = decoder_block(b, e7, 512,norm=False)\n",
        "\td2 = decoder_block(d1, e6, 512)\n",
        "\td3 = decoder_block(d2, e5, 512,)\n",
        "\td4 = decoder_block(d3, e4, 512,dropout=False)\n",
        "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\tmodel = Model(in_image, out_image,name='generator')\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "b7r0P5gmI2nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the GAN model and its methods"
      ],
      "metadata": {
        "id": "fGSOR-irOV4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_gan(g_model, d_model, image_shape): #Defines a forward pass of the GAN model\n",
        "\tfor layer in d_model.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\tin_src = Input(shape=image_shape)\n",
        "\tgen_out = g_model(in_src)\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\tmodel = Model(in_src, [dis_out,gen_out])\n",
        "\topt = Adam(learning_rate=0.0002,beta_1=0.5)\n",
        "\tmodel.compile(loss=[generator_loss,'mae'], optimizer=opt, loss_weights=[1,100]) #Mean absolute error is added as well with a weightage of 100, as this has been shown to have best performance with GAN\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def generate_real_samples(trainA,trainB, n_samples, patch_shape,tr=True): #Samples real hazy images and groun truth images from the dataset\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\tif tr:\n",
        "\t\tfor i in range(n_samples):\n",
        "\t\t\tX1[i],X2[i]=random_jitter(X1[i],X2[i])\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y\n",
        "\n",
        "\n",
        "def generate_fake_samples(g_model, samples, patch_shape,): #Samples real hazy images and generates fake clear images for the corresponding sample of hazy images\n",
        "\tX = g_model.predict(samples)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "psn_c=list()\n",
        "def summarize_performance(step, g_model, trainA,trainB,testA,testB, n_samples=tr,x_samples=test_size): #Check performance of model through quantitative and qualitative (visual) inspection\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(trainA,trainB, n_samples, 1,tr=False)\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "\tX_realB = (X_realB + 1) / 2.0\n",
        "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
        "\tpsn=list()\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpsn.append(psnr(X_realB[i],X_fakeB[i]))\n",
        "\tprint(\"Training: Average psnr[%f] Variance[%f] Max[%f]\"%(np.average(psn),np.var(psn),np.max(psn)))\n",
        "\tpsn=list()\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(testA,testB, x_samples, 1,tr=False)\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "\tX_realB = (X_realB + 1) / 2.0\n",
        "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
        "\tfor i in range(x_samples):\n",
        "\t\tpsn.append(psnr(X_realB[i],X_fakeB[i]))\n",
        "\tprint(\"Testing: Average psnr[%f] Variance[%f] Max[%f]\"%(np.average(psn),np.var(psn),np.max(psn)))\n",
        "\tpsn_c.append(np.average(psn))\n",
        "\tdel psn\n",
        "\tgc.collect()\n",
        "\n",
        "\n",
        "def train(d_model, g_model, gan_model, trainA,trainB,testA,testB, n_epochs=100, n_batch=8): #Code for training the model. We first train the discriminator and then train the generator.\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\thalf_batch=int(n_batch/2)+bool(n_batch==1)\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\tg_hist,g1,d1,d2=list(),list(),list(),list()\n",
        "\tfor i in range(n_steps):\n",
        "\t\tn_disc=1\n",
        "\t\tct1=0\n",
        "\t\tct2=0\n",
        "\t\tfor j in range(n_disc):\n",
        "\t\t\t[X_realA, X_realB], y_real = generate_real_samples(trainA,trainB, half_batch, n_patch)\n",
        "\t\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\t\tct1=ct1+d_loss1\n",
        "\t\t\tct2=ct2+d_loss2\n",
        "\t\t\tdel X_realA\n",
        "\t\t\tdel X_realB\n",
        "\t\t\tdel X_fakeB\n",
        "\t\t\tdel y_real\n",
        "\t\t\tdel y_fake\n",
        "\t\t\tgc.collect()\n",
        "\t\td1.append(ct1/n_disc)\n",
        "\t\td2.append(ct2/n_disc)\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(trainA,trainB, n_batch, n_patch)\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\tx1,x2,x3 = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\tg_hist.append(x2)\n",
        "\t\tg1.append(x3)\n",
        "\t\tprint('>%d, d1[%f] d2[%f] v_loss[%f] l1_loss[%f]' % (i+1, d_loss1,d_loss2,x2,x3))\n",
        "\t\tdel X_realA\n",
        "\t\tdel X_realB\n",
        "\t\tdel X_fakeB\n",
        "\t\tdel y_real\n",
        "\t\tdel y_fake\n",
        "\t\tgc.collect()\n",
        "\t\tif (i+1) % (bat_per_epo*2) == 0:\n",
        "\t\t\t\tsummarize_performance(step=i, g_model=g_model,trainA=trainA,trainB=trainB,testA=testA,testB=testB,)\n",
        "\t\t\t\tplot_history(g_hist,g1,d1,d2)\n",
        "\n",
        "\n",
        "d_model = define_discriminator(image_shape)\n",
        "g_model = define_generator(image_shape)\n",
        "gan_model = define_gan(g_model, d_model, image_shape)"
      ],
      "metadata": {
        "id": "OY3FjaZZ7gmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(d_model=d_model, g_model=g_model, gan_model=gan_model,trainA=hazy1,trainB=clear1,testA=hazy2,testB=clear2)"
      ],
      "metadata": {
        "id": "iGQqrE-b8FOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training is done, we can test our model by changing the value of 'i' in the code"
      ],
      "metadata": {
        "id": "X9US7VWQByE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i=0\n",
        "i=i%hazy2.shape[0]\n",
        "X_realB = (clear2[i] + 1) / 2.0\n",
        "img=np.expand_dims(hazy2[i],axis=0)\n",
        "X_fakeB = (g_model.predict(img) + 1) / 2.0\n",
        "print(psnr(X_realB,X_fakeB))\n",
        "plt.imshow((hazy2[i] + 1)/2.0)\n",
        "plt.title('Hazy Image')\n",
        "plt.show()\n",
        "plt.imshow((X_fakeB[0]+1)/2.0)\n",
        "plt.title('Generated Image')\n",
        "plt.show()\n",
        "plt.imshow((X_realB[0]+1)/2.0)\n",
        "plt.title('Clear image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K31234888OzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQCB7RSlA_gQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}